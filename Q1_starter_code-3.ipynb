{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0011f96d",
      "metadata": {
        "id": "0011f96d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b74ea495",
      "metadata": {
        "id": "b74ea495"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"exam_data (1).csv\")\n",
        "\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Improving a given ANN model on a tabular dataset by:***"
      ],
      "metadata": {
        "id": "IgqR1Hvby1VM"
      },
      "id": "IgqR1Hvby1VM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We should only fit the StandardScaler on your training data to prevent data leakage.**"
      ],
      "metadata": {
        "id": "J_JmVHgJyQE8"
      },
      "id": "J_JmVHgJyQE8"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9cc10d52",
      "metadata": {
        "id": "9cc10d52"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Train / validation split\n",
        "# -------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "#ISSUE to be fixed\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)   # <-- FIX: Use transform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. Explain why it is a problem and how your fix helps\n",
        "\n",
        "Ans. Previously it was fiting the x validation also so it was a mistake and will occure problem on our model"
      ],
      "metadata": {
        "id": "m7vWVejj5EBJ"
      },
      "id": "m7vWVejj5EBJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fixing a hidden mistake** AND **Changing the model architecture**"
      ],
      "metadata": {
        "id": "7ItBXqxhzH8R"
      },
      "id": "7ItBXqxhzH8R"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ac1ee21c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac1ee21c",
        "outputId": "429a9563-99c6-4609-d4f5-a6ea55997866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.6561 - loss: 0.6291 - val_accuracy: 0.8125 - val_loss: 0.5172\n",
            "Epoch 2/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8150 - loss: 0.4585 - val_accuracy: 0.8750 - val_loss: 0.4032\n",
            "Epoch 3/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9050 - loss: 0.3127 - val_accuracy: 0.9000 - val_loss: 0.3237\n",
            "Epoch 4/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9163 - loss: 0.2352 - val_accuracy: 0.9125 - val_loss: 0.2683\n",
            "Epoch 5/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9007 - loss: 0.2323 - val_accuracy: 0.9000 - val_loss: 0.2440\n",
            "Epoch 6/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9317 - loss: 0.1909 - val_accuracy: 0.8875 - val_loss: 0.2234\n",
            "Epoch 7/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9469 - loss: 0.1445 - val_accuracy: 0.9125 - val_loss: 0.2117\n",
            "Epoch 8/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9575 - loss: 0.1454 - val_accuracy: 0.9125 - val_loss: 0.2020\n",
            "Epoch 9/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9734 - loss: 0.0954 - val_accuracy: 0.9125 - val_loss: 0.2091\n",
            "Epoch 10/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.1181 - val_accuracy: 0.9000 - val_loss: 0.1909\n",
            "Epoch 11/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9716 - loss: 0.1081 - val_accuracy: 0.9000 - val_loss: 0.1967\n",
            "Epoch 12/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.0891 - val_accuracy: 0.9125 - val_loss: 0.2130\n",
            "Epoch 13/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9755 - loss: 0.0688 - val_accuracy: 0.9125 - val_loss: 0.1988\n",
            "Epoch 14/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0681 - val_accuracy: 0.9250 - val_loss: 0.1649\n",
            "Epoch 15/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0628 - val_accuracy: 0.9125 - val_loss: 0.1535\n",
            "Epoch 16/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0577 - val_accuracy: 0.9250 - val_loss: 0.1700\n",
            "Epoch 17/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0307 - val_accuracy: 0.9125 - val_loss: 0.1636\n",
            "Epoch 18/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0427 - val_accuracy: 0.9375 - val_loss: 0.1524\n",
            "Epoch 19/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0439 - val_accuracy: 0.9250 - val_loss: 0.1615\n",
            "Epoch 20/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0314 - val_accuracy: 0.9375 - val_loss: 0.1894\n",
            "Epoch 21/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0184 - val_accuracy: 0.9250 - val_loss: 0.2290\n",
            "Epoch 22/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0264 - val_accuracy: 0.9500 - val_loss: 0.1692\n",
            "Epoch 23/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0153 - val_accuracy: 0.9375 - val_loss: 0.1482\n",
            "Epoch 24/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0158 - val_accuracy: 0.9375 - val_loss: 0.2042\n",
            "Epoch 25/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0446 - val_accuracy: 0.9375 - val_loss: 0.2462\n",
            "Epoch 26/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.0393 - val_accuracy: 0.9375 - val_loss: 0.1615\n",
            "Epoch 27/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0162 - val_accuracy: 0.9375 - val_loss: 0.1584\n",
            "Epoch 28/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.0488 - val_accuracy: 0.9250 - val_loss: 0.3311\n",
            "Epoch 29/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0102 - val_accuracy: 0.9375 - val_loss: 0.2901\n",
            "Epoch 30/30\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0279 - val_accuracy: 0.9375 - val_loss: 0.2555\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# NEW ANN (STRONG DESIGN)\n",
        "# -------------------------\n",
        "\n",
        "#now improving\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2), #USING DROPOUT SO IT DONT OVERFIT AND IMPROVING GENERALIZATION\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#improved the model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain why you made each architectural change.\n",
        "\n",
        "The previous architecture was not having neurons and there was only few layers and no generalization, i have added more layers with regularization"
      ],
      "metadata": {
        "id": "lnywd7Dy4tFi"
      },
      "id": "lnywd7Dy4tFi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing prediction behavior**"
      ],
      "metadata": {
        "id": "NXqYbJf-10Fy"
      },
      "id": "NXqYbJf-10Fy"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "58f338c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58f338c9",
        "outputId": "f1697be5-ef86-4a10-98a1-b104c3e73874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c8eb195bf60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 217ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c8eb195bf60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "\n",
            "Final Training Accuracy: 0.9969\n",
            "Final Validation Accuracy: 0.9375\n",
            "Confusion Matrix:\n",
            " [[50  1]\n",
            " [ 4 25]]\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "probs = model.predict(X_val)\n",
        "\n",
        "# üëâ Students change threshold here\n",
        "# I change from 0.5 to 0.65\n",
        "threshold = 0.65\n",
        "preds = (probs > threshold).astype(int)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_val, preds)\n",
        "\n",
        "print(\"\\nFinal Training Accuracy:\", round(history.history['accuracy'][-1], 4))\n",
        "print(\"Final Validation Accuracy:\", round(history.history['val_accuracy'][-1], 4))\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# BEFORE THE TRAINING ACCURACY WAS 94% NOW IS 99%\n",
        "# BEFORE THE VALIDATION ACCURACY WAS 88% NOW IS 93%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. Which class benefited?\n",
        "\n",
        "\n",
        "Ans. The both classes benefitted as the model improved amazingly and impacting both the classes\n",
        "\n",
        "Q. Why accuracy may not change much but confusion matrix does?\n",
        "\n",
        "Ans. The accuracy is not dependent on confusion matrix but the confusion matrix tells us the what was the actual value of that class and what we predicted"
      ],
      "metadata": {
        "id": "XNCFHRE83r2i"
      },
      "id": "XNCFHRE83r2i"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "8dba115a",
      "metadata": {
        "id": "8dba115a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, confusion_matrix, classification_report)\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Read Dataset & Ignore Date/Time\n",
        "def load_and_clean_columns(filepath, columns_to_drop):\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, sep=';', decimal=',')\n",
        "\n",
        "\n",
        "        # Drop columns if they exist\n",
        "        df.drop(columns=[col for col in columns_to_drop if col in df.columns], axis=1, inplace=True)\n",
        "        print(f\"Dataset loaded. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing (Missing, Duplicates, Zero Sum Cols)\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Handles missing values, duplicates, and drops zero-sum columns.\n",
        "    \"\"\"\n",
        "    initial_shape = df.shape\n",
        "\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    df = df.dropna()\n",
        "\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    cols_sum_zero = [col for col in numeric_cols if df[col].sum() == 0]\n",
        "    df.drop(columns=cols_sum_zero, axis=1, inplace=True)\n",
        "\n",
        "    print(f\"Preprocessing complete. Rows dropped: {initial_shape[0] - df.shape[0]}. New Shape: {df.shape}\")\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "CH3vEM0N0PD3"
      },
      "id": "CH3vEM0N0PD3",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Correlation & Feature Selection\n",
        "def select_features_by_correlation(df, target_col, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Calculates correlation with label, filters by threshold,\n",
        "    and returns selected feature names and a summary dataframe.\n",
        "    \"\"\"\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found in dataframe.\")\n",
        "\n",
        "    corr_matrix = df.corr()\n",
        "\n",
        "    target_corr = corr_matrix[target_col].drop(target_col) # Drop target itself\n",
        "\n",
        "    target_corr_sorted = target_corr.abs().sort_values(ascending=False)\n",
        "\n",
        "    selected_features = target_corr_sorted[target_corr_sorted > threshold].index.tolist()\n",
        "\n",
        "    corr_df = pd.DataFrame({\n",
        "        'Feature Name': selected_features,\n",
        "        'Correlation Score': target_corr_sorted[selected_features].values\n",
        "    })\n",
        "\n",
        "    print(f\"\\n--- Feature Selection (Threshold > {threshold}) ---\")\n",
        "    print(corr_df)\n",
        "\n",
        "    return selected_features, corr_df\n"
      ],
      "metadata": {
        "id": "HV8KsFel7P9n"
      },
      "id": "HV8KsFel7P9n",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Standard Scaler\n",
        "def scale_features(X_data):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_data)\n",
        "    return X_scaled"
      ],
      "metadata": {
        "id": "ufNiWN6K7V-I"
      },
      "id": "ufNiWN6K7V-I",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, model_name, params_desc, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\nResults for: {model_name} | Params: {params_desc}\")\n",
        "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix: {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "    return {'Model': model_name, 'Params': params_desc, 'Accuracy': acc, 'F1': f1}"
      ],
      "metadata": {
        "id": "r15XkY447oqx"
      },
      "id": "r15XkY447oqx",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- CONFIGURATION ---\n",
        "dataset_path = 'df_kwh_adjusted.csv'\n",
        "\n",
        "target_col_name = 'label'\n",
        "\n",
        "cols_to_ignore = ['date', 'time', 'day', 'Unnamed: 0']\n",
        "\n",
        "# 1. Read Data\n",
        "df = load_and_clean_columns(dataset_path, cols_to_ignore)\n",
        "\n",
        "# 2. Preprocessing\n",
        "df = preprocess_data(df)\n",
        "\n",
        "if target_col_name not in df.columns:\n",
        "    print(f\"CRITICAL ERROR: Column '{target_col_name}' not found. Please update 'target_col_name' in main().\")\n",
        "    # For demonstration purposes, I will create a dummy target if it's missing so code runs\n",
        "    print(\"Creating dummy target for demonstration...\")\n",
        "    df[target_col_name] = np.random.randint(0, 2, df.shape[0])\n",
        "\n",
        "# 3. Feature Selection\n",
        "selected_feats, corr_info = select_features_by_correlation(df, target_col_name, threshold=0.01)\n",
        "\n",
        "\n",
        "if len(selected_feats) == 0:\n",
        "    print(\"No features met the threshold. Lower the threshold or check data.\")\n",
        "\n",
        "X = df[selected_feats]\n",
        "y = df[target_col_name]\n",
        "\n",
        "\n",
        "X_scaled = scale_features(X)\n",
        "\n",
        "X_unscaled = X.values\n",
        "\n",
        "feature_sets = {\n",
        "    \"Set1 (Scaled)\": X_scaled,\n",
        "    \"Set2 (Unscaled)\": X_unscaled\n",
        "}\n",
        "\n",
        "\n",
        "models_config = [\n",
        "    # Naive Bayes (GaussianNB doesn't have many hyperparameters to tune, usually just var_smoothing)\n",
        "    (\"Naive Bayes\", GaussianNB(), [{\"var_smoothing\": 1e-9}, {\"var_smoothing\": 1e-8}, {\"var_smoothing\": 1e-7}, {\"var_smoothing\": 1e-6}, {\"var_smoothing\": 1e-5}]),\n",
        "\n",
        "    # Decision Tree (Criteria, MaxDepth)\n",
        "    (\"Decision Tree\", DecisionTreeClassifier(), [\n",
        "        {\"criterion\": \"gini\", \"max_depth\": 3},\n",
        "        {\"criterion\": \"entropy\", \"max_depth\": 5},\n",
        "        {\"criterion\": \"gini\", \"max_depth\": 10},\n",
        "        {\"criterion\": \"entropy\", \"max_depth\": None},\n",
        "        {\"splitter\": \"random\", \"max_depth\": 5}\n",
        "    ]),\n",
        "\n",
        "    # Random Forest (N_estimators, MaxDepth)\n",
        "    (\"Random Forest\", RandomForestClassifier(), [\n",
        "        {\"n_estimators\": 10, \"max_depth\": 5},\n",
        "        {\"n_estimators\": 50, \"max_depth\": 10},\n",
        "        {\"n_estimators\": 100, \"criterion\": \"entropy\"},\n",
        "        {\"n_estimators\": 20, \"max_features\": \"log2\"},\n",
        "        {\"n_estimators\": 50, \"max_depth\": None}\n",
        "    ]),\n",
        "\n",
        "    # KNN (n_neighbors, weights)\n",
        "    (\"KNN\", KNeighborsClassifier(), [\n",
        "        {\"n_neighbors\": 3},\n",
        "        {\"n_neighbors\": 5},\n",
        "        {\"n_neighbors\": 7, \"weights\": \"distance\"},\n",
        "        {\"n_neighbors\": 9},\n",
        "        {\"n_neighbors\": 5, \"metric\": \"manhattan\"}\n",
        "    ]),\n",
        "\n",
        "    # Logistic Regression (C, penalty)\n",
        "    (\"Logistic Regression\", LogisticRegression(max_iter=1000), [\n",
        "        {\"C\": 1.0, \"solver\": \"lbfgs\"},\n",
        "        {\"C\": 0.1, \"solver\": \"lbfgs\"},\n",
        "        {\"C\": 10.0, \"solver\": \"liblinear\"},\n",
        "        {\"C\": 0.01, \"solver\": \"liblinear\"},\n",
        "        {\"C\": 5.0, \"solver\": \"lbfgs\"}\n",
        "    ])\n",
        "]\n",
        "\n",
        "best_outcome = {'Score': 0, 'Info': ''}\n",
        "\n",
        "for set_name, X_data in feature_sets.items():\n",
        "    print(f\"\\n{'='*20} Processing {set_name} {'='*20}\")\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    for name, model_obj, param_list in models_config:\n",
        "\n",
        "        # Run 5 iterations with different parameters\n",
        "        for params in param_list:\n",
        "            # Set parameters\n",
        "            model_obj.set_params(**params)\n",
        "\n",
        "            # Train and Evaluate\n",
        "            res = train_and_evaluate(model_obj, name, str(params), X_train, X_test, y_train, y_test)\n",
        "\n",
        "            # Check best outcome\n",
        "            if res['Accuracy'] > best_outcome['Score']:\n",
        "                best_outcome['Score'] = res['Accuracy']\n",
        "                best_outcome['Info'] = f\"{name} with {params} on {set_name}\"\n",
        "\n",
        "print(f\"BEST OUTCOME: {best_outcome['Info']} with Accuracy: {best_outcome['Score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uanQM1l-72eM",
        "outputId": "97b7f995-c3cb-4a59-fddf-7b99bcf7d75f"
      },
      "id": "uanQM1l-72eM",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded. Shape: (8354, 370)\n",
            "Preprocessing complete. Rows dropped: 1734. New Shape: (6620, 370)\n",
            "CRITICAL ERROR: Column 'label' not found. Please update 'target_col_name' in main().\n",
            "Creating dummy target for demonstration...\n",
            "\n",
            "--- Feature Selection (Threshold > 0.01) ---\n",
            "   Feature Name  Correlation Score\n",
            "0        MT_290           0.030125\n",
            "1        MT_314           0.025638\n",
            "2        MT_231           0.025187\n",
            "3        MT_211           0.022547\n",
            "4        MT_294           0.020792\n",
            "5        MT_207           0.019138\n",
            "6        MT_245           0.018847\n",
            "7        MT_257           0.016989\n",
            "8        MT_219           0.016981\n",
            "9        MT_218           0.016046\n",
            "10       MT_220           0.015788\n",
            "11       MT_261           0.015736\n",
            "12       MT_208           0.014683\n",
            "13       MT_317           0.014650\n",
            "14       MT_217           0.013145\n",
            "15       MT_223           0.012679\n",
            "16       MT_246           0.012577\n",
            "17       MT_215           0.012452\n",
            "18       MT_244           0.012138\n",
            "19       MT_210           0.011755\n",
            "20       MT_159           0.011733\n",
            "21       MT_326           0.011733\n",
            "22       MT_212           0.011672\n",
            "23       MT_306           0.011483\n",
            "24       MT_204           0.011446\n",
            "25       MT_284           0.011105\n",
            "26       MT_279           0.010990\n",
            "27       MT_205           0.010385\n",
            "28       MT_214           0.010122\n",
            "\n",
            "==================== Processing Set1 (Scaled) ====================\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-09}\n",
            "Accuracy: 0.5015, Precision: 0.5395, Recall: 0.5015, F1: 0.3863\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.07      0.13       674\n",
            "           1       0.50      0.94      0.65       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.54      0.51      0.39      1324\n",
            "weighted avg       0.54      0.50      0.39      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-08}\n",
            "Accuracy: 0.5015, Precision: 0.5395, Recall: 0.5015, F1: 0.3863\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.07      0.13       674\n",
            "           1       0.50      0.94      0.65       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.54      0.51      0.39      1324\n",
            "weighted avg       0.54      0.50      0.39      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-07}\n",
            "Accuracy: 0.4985, Precision: 0.5237, Recall: 0.4985, F1: 0.3874\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.08      0.14       674\n",
            "           1       0.49      0.93      0.65       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.52      0.51      0.39      1324\n",
            "weighted avg       0.52      0.50      0.39      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-06}\n",
            "Accuracy: 0.4985, Precision: 0.5212, Recall: 0.4985, F1: 0.3921\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.09      0.15       674\n",
            "           1       0.49      0.93      0.64       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.52      0.51      0.40      1324\n",
            "weighted avg       0.52      0.50      0.39      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-05}\n",
            "Accuracy: 0.4992, Precision: 0.5235, Recall: 0.4992, F1: 0.3935\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.09      0.15       674\n",
            "           1       0.49      0.93      0.64       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.52      0.51      0.40      1324\n",
            "weighted avg       0.52      0.50      0.39      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'gini', 'max_depth': 3}\n",
            "Accuracy: 0.4992, Precision: 0.4991, Recall: 0.4992, F1: 0.4992\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.51      0.51       674\n",
            "           1       0.49      0.48      0.49       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.50      0.50      0.50      1324\n",
            "weighted avg       0.50      0.50      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'entropy', 'max_depth': 5}\n",
            "Accuracy: 0.4992, Precision: 0.4991, Recall: 0.4992, F1: 0.4992\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.51      0.51       674\n",
            "           1       0.49      0.48      0.49       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.50      0.50      0.50      1324\n",
            "weighted avg       0.50      0.50      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'gini', 'max_depth': 10}\n",
            "Accuracy: 0.4955, Precision: 0.4960, Recall: 0.4955, F1: 0.4953\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.47      0.49       674\n",
            "           1       0.49      0.52      0.50       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.50      0.50      0.50      1324\n",
            "weighted avg       0.50      0.50      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'entropy', 'max_depth': None}\n",
            "Accuracy: 0.4977, Precision: 0.4951, Recall: 0.4977, F1: 0.4884\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.63      0.56       674\n",
            "           1       0.48      0.36      0.41       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.49      0.50      0.49      1324\n",
            "weighted avg       0.50      0.50      0.49      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'splitter': 'random', 'max_depth': 5}\n",
            "Accuracy: 0.5091, Precision: 0.5047, Recall: 0.5091, F1: 0.3589\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.98      0.67       674\n",
            "           1       0.50      0.02      0.04       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.50      0.50      0.35      1324\n",
            "weighted avg       0.50      0.51      0.36      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 10, 'max_depth': 5}\n",
            "Accuracy: 0.4962, Precision: 0.4826, Recall: 0.4962, F1: 0.4323\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.82      0.63       674\n",
            "           1       0.46      0.16      0.23       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.48      0.49      0.43      1324\n",
            "weighted avg       0.48      0.50      0.43      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 50, 'max_depth': 10}\n",
            "Accuracy: 0.5076, Precision: 0.5060, Recall: 0.5076, F1: 0.5017\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.61      0.56       674\n",
            "           1       0.50      0.40      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 100, 'criterion': 'entropy'}\n",
            "Accuracy: 0.5136, Precision: 0.5123, Recall: 0.5136, F1: 0.5073\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.62      0.57       674\n",
            "           1       0.51      0.40      0.45       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.51      1324\n",
            "weighted avg       0.51      0.51      0.51      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 20, 'max_features': 'log2'}\n",
            "Accuracy: 0.5128, Precision: 0.5114, Recall: 0.5128, F1: 0.5046\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.64      0.57       674\n",
            "           1       0.51      0.38      0.43       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 50, 'max_depth': None}\n",
            "Accuracy: 0.4962, Precision: 0.4945, Recall: 0.4962, F1: 0.4917\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.59      0.54       674\n",
            "           1       0.48      0.40      0.44       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.49      0.49      0.49      1324\n",
            "weighted avg       0.49      0.50      0.49      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 3}\n",
            "Accuracy: 0.5174, Precision: 0.5188, Recall: 0.5174, F1: 0.5159\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.46      0.49       674\n",
            "           1       0.51      0.58      0.54       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.52      1324\n",
            "weighted avg       0.52      0.52      0.52      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 5}\n",
            "Accuracy: 0.5196, Precision: 0.5215, Recall: 0.5196, F1: 0.5173\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.45      0.49       674\n",
            "           1       0.51      0.59      0.55       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.52      1324\n",
            "weighted avg       0.52      0.52      0.52      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 7, 'weights': 'distance'}\n",
            "Accuracy: 0.5249, Precision: 0.5259, Recall: 0.5249, F1: 0.5244\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.49      0.51       674\n",
            "           1       0.51      0.56      0.54       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.53      0.53      0.52      1324\n",
            "weighted avg       0.53      0.52      0.52      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 9}\n",
            "Accuracy: 0.5151, Precision: 0.5161, Recall: 0.5151, F1: 0.5144\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.48      0.50       674\n",
            "           1       0.51      0.56      0.53       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.51      1324\n",
            "weighted avg       0.52      0.52      0.51      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 5, 'metric': 'manhattan'}\n",
            "Accuracy: 0.5181, Precision: 0.5198, Recall: 0.5181, F1: 0.5163\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.46      0.49       674\n",
            "           1       0.51      0.58      0.54       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.52      1324\n",
            "weighted avg       0.52      0.52      0.52      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 1.0, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5121, Precision: 0.5107, Recall: 0.5121, F1: 0.5052\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.51      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 0.1, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5121, Precision: 0.5106, Recall: 0.5121, F1: 0.5051\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.51      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 10.0, 'solver': 'liblinear'}\n",
            "Accuracy: 0.5113, Precision: 0.5099, Recall: 0.5113, F1: 0.5046\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 0.01, 'solver': 'liblinear'}\n",
            "Accuracy: 0.5113, Precision: 0.5098, Recall: 0.5113, F1: 0.5044\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 5.0, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5121, Precision: 0.5107, Recall: 0.5121, F1: 0.5052\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.51      1324\n",
            "\n",
            "\n",
            "==================== Processing Set2 (Unscaled) ====================\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-09}\n",
            "Accuracy: 0.4992, Precision: 0.5231, Recall: 0.4992, F1: 0.3944\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.09      0.15       674\n",
            "           1       0.49      0.92      0.64       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.52      0.51      0.40      1324\n",
            "weighted avg       0.52      0.50      0.39      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-08}\n",
            "Accuracy: 0.5008, Precision: 0.5271, Recall: 0.5008, F1: 0.3981\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.09      0.16       674\n",
            "           1       0.50      0.92      0.64       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.53      0.51      0.40      1324\n",
            "weighted avg       0.53      0.50      0.40      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-07}\n",
            "Accuracy: 0.5008, Precision: 0.5271, Recall: 0.5008, F1: 0.3981\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.09      0.16       674\n",
            "           1       0.50      0.92      0.64       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.53      0.51      0.40      1324\n",
            "weighted avg       0.53      0.50      0.40      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-06}\n",
            "Accuracy: 0.5023, Precision: 0.5314, Recall: 0.5023, F1: 0.4008\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.10      0.16       674\n",
            "           1       0.50      0.92      0.65       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.53      0.51      0.41      1324\n",
            "weighted avg       0.53      0.50      0.40      1324\n",
            "\n",
            "\n",
            "Results for: Naive Bayes | Params: {'var_smoothing': 1e-05}\n",
            "Accuracy: 0.4977, Precision: 0.5089, Recall: 0.4977, F1: 0.4248\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.15      0.23       674\n",
            "           1       0.49      0.86      0.63       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.51      0.50      0.43      1324\n",
            "weighted avg       0.51      0.50      0.42      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'gini', 'max_depth': 3}\n",
            "Accuracy: 0.5060, Precision: 0.4593, Recall: 0.5060, F1: 0.3537\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.98      0.67       674\n",
            "           1       0.41      0.01      0.03       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.46      0.50      0.35      1324\n",
            "weighted avg       0.46      0.51      0.35      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'entropy', 'max_depth': 5}\n",
            "Accuracy: 0.4894, Precision: 0.4904, Recall: 0.4894, F1: 0.4881\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.44      0.47       674\n",
            "           1       0.48      0.54      0.51       650\n",
            "\n",
            "    accuracy                           0.49      1324\n",
            "   macro avg       0.49      0.49      0.49      1324\n",
            "weighted avg       0.49      0.49      0.49      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'gini', 'max_depth': 10}\n",
            "Accuracy: 0.4940, Precision: 0.4951, Recall: 0.4940, F1: 0.4923\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.44      0.47       674\n",
            "           1       0.49      0.55      0.52       650\n",
            "\n",
            "    accuracy                           0.49      1324\n",
            "   macro avg       0.49      0.49      0.49      1324\n",
            "weighted avg       0.50      0.49      0.49      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'criterion': 'entropy', 'max_depth': None}\n",
            "Accuracy: 0.5068, Precision: 0.5051, Recall: 0.5068, F1: 0.5000\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.62      0.56       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.50      0.50      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Decision Tree | Params: {'splitter': 'random', 'max_depth': 5}\n",
            "Accuracy: 0.4970, Precision: 0.4966, Recall: 0.4970, F1: 0.4965\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.53      0.52       674\n",
            "           1       0.49      0.46      0.48       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.50      0.50      0.50      1324\n",
            "weighted avg       0.50      0.50      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 10, 'max_depth': 5}\n",
            "Accuracy: 0.5023, Precision: 0.4970, Recall: 0.5023, F1: 0.4677\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.75      0.61       674\n",
            "           1       0.49      0.24      0.32       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.50      0.50      0.47      1324\n",
            "weighted avg       0.50      0.50      0.47      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 50, 'max_depth': 10}\n",
            "Accuracy: 0.5076, Precision: 0.5064, Recall: 0.5076, F1: 0.5044\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.59      0.55       674\n",
            "           1       0.50      0.43      0.46       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 100, 'criterion': 'entropy'}\n",
            "Accuracy: 0.5083, Precision: 0.5061, Recall: 0.5083, F1: 0.4952\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.67      0.58       674\n",
            "           1       0.50      0.34      0.41       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.49      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 20, 'max_features': 'log2'}\n",
            "Accuracy: 0.5151, Precision: 0.5139, Recall: 0.5151, F1: 0.5087\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.51      0.40      0.45       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.51      0.51      0.51      1324\n",
            "weighted avg       0.51      0.52      0.51      1324\n",
            "\n",
            "\n",
            "Results for: Random Forest | Params: {'n_estimators': 50, 'max_depth': None}\n",
            "Accuracy: 0.4970, Precision: 0.4954, Recall: 0.4970, F1: 0.4931\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.58      0.54       674\n",
            "           1       0.49      0.41      0.44       650\n",
            "\n",
            "    accuracy                           0.50      1324\n",
            "   macro avg       0.50      0.50      0.49      1324\n",
            "weighted avg       0.50      0.50      0.49      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 3}\n",
            "Accuracy: 0.5219, Precision: 0.5234, Recall: 0.5219, F1: 0.5206\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.47      0.50       674\n",
            "           1       0.51      0.58      0.54       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.52      1324\n",
            "weighted avg       0.52      0.52      0.52      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 5}\n",
            "Accuracy: 0.5136, Precision: 0.5150, Recall: 0.5136, F1: 0.5120\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.46      0.49       674\n",
            "           1       0.50      0.57      0.54       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.51      1324\n",
            "weighted avg       0.52      0.51      0.51      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 7, 'weights': 'distance'}\n",
            "Accuracy: 0.5196, Precision: 0.5203, Recall: 0.5196, F1: 0.5194\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.50      0.51       674\n",
            "           1       0.51      0.54      0.53       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.52      1324\n",
            "weighted avg       0.52      0.52      0.52      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 9}\n",
            "Accuracy: 0.5060, Precision: 0.5067, Recall: 0.5060, F1: 0.5057\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.48      0.50       674\n",
            "           1       0.50      0.53      0.51       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.51      1324\n",
            "weighted avg       0.51      0.51      0.51      1324\n",
            "\n",
            "\n",
            "Results for: KNN | Params: {'n_neighbors': 5, 'metric': 'manhattan'}\n",
            "Accuracy: 0.5136, Precision: 0.5150, Recall: 0.5136, F1: 0.5120\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.46      0.49       674\n",
            "           1       0.50      0.57      0.54       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.51      1324\n",
            "weighted avg       0.52      0.51      0.51      1324\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for: Logistic Regression | Params: {'C': 1.0, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5136, Precision: 0.5123, Recall: 0.5136, F1: 0.5071\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.51      0.40      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.51      1324\n",
            "weighted avg       0.51      0.51      0.51      1324\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for: Logistic Regression | Params: {'C': 0.1, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5098, Precision: 0.5083, Recall: 0.5098, F1: 0.5032\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.62      0.56       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 10.0, 'solver': 'liblinear'}\n",
            "Accuracy: 0.5113, Precision: 0.5099, Recall: 0.5113, F1: 0.5046\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 0.01, 'solver': 'liblinear'}\n",
            "Accuracy: 0.5204, Precision: 0.5194, Recall: 0.5204, F1: 0.5134\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.64      0.58       674\n",
            "           1       0.51      0.40      0.45       650\n",
            "\n",
            "    accuracy                           0.52      1324\n",
            "   macro avg       0.52      0.52      0.51      1324\n",
            "weighted avg       0.52      0.52      0.51      1324\n",
            "\n",
            "\n",
            "Results for: Logistic Regression | Params: {'C': 5.0, 'solver': 'lbfgs'}\n",
            "Accuracy: 0.5106, Precision: 0.5090, Recall: 0.5106, F1: 0.5035\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.63      0.57       674\n",
            "           1       0.50      0.39      0.44       650\n",
            "\n",
            "    accuracy                           0.51      1324\n",
            "   macro avg       0.51      0.51      0.50      1324\n",
            "weighted avg       0.51      0.51      0.50      1324\n",
            "\n",
            "BEST OUTCOME: KNN with {'n_neighbors': 7, 'weights': 'distance'} on Set1 (Scaled) with Accuracy: 0.5249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZCFdJ0E9V7M"
      },
      "id": "_ZCFdJ0E9V7M",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}